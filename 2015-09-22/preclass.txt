0.  How much time did you spend on this pre-class exercise, and when?
2 hours, late Monday night. I really wish I could both do these exercises and
sleep, but by the time I finish watching all the lectures it's usually night 
already.

1.  What are one or two points that you found least clear in the
    9/22 slide decks (including the narration)?
	
I don't remember enough statistics to see the connection between the standard
deviation of R given by the Central Limit Theorem and the code on the next slide
that uses sum_fX2. Why is sqrt(sum_fX2-sum_fX*sum_fx/i)/i an estimate of 
(standard deviation of f(X))/(sqrt(n))?

You said that getting good seeds for independent RNGs per thread was difficult,
and that it requires an RNG with a "very long period," but you then say that 
your solution uses a different seed per thread for a Mersenne Twister RNG. Is
the Mersenne Twister an RNG with a "very long period"? Or are you doing 
something clever here to make sure the streams generated by the per-thread RNGs
are uncorrelated?

2.  The pthread_mc.c file in the demo subdirectory runs a Monte Carlo
    simulation to estimate the expected value of a uniform random
    variable.  The "-p" option sets the number of processors used,
    while "-b" sets the number of trials between synchronizations.

    a) Write a model for the run time for this simulation code in
       terms of the number of trials (N), number of processors (p),
       time per trial (t_trial), and time to update the global
       counters in the critical section (t_update).
	   
Write a model? Uh, what's that mean? An equation? I know that the runtime should
increase with the product of number of trials and time per trial, and decrease 
with the number of processors as long as the time in the critical section isn't
too long, but I don't know what constants I should use to relate those. Maybe
it should be based on Amdahl's Law:

Time = (Serial execution time)(Fraction of serial code + (Fraction of parallel code)/p)
Time = (N*(t_trial+t_update))
       *(t_update/(t_trial+t_update) + (t_trial/(t_trial+t_update))/p)

    b) Run the code with a few different parameter values in order
       to estimate N, t_trial, and t_update for this code on
       a totient compute node.

N seems to be 1000000 plus p * the batch size, which makes sense because 1000000 
is the hardcoded trial limit; the total number of trials overshoots this by one 
batch size per thread. I don't know why we're "estimating" N. 
To estimate t_trial, I used a single thread with a batch size of 1000000, so 
that global updates were done only twice. This resulted in an estimate of 
t_trial = .014009 / 2000000 = 7.0045e-9 seconds.
To estimate t_update, I used a single thread with a batch size of 2, so that 
global updates were done after every 2 trials. (Batch size of 1 did not work, 
as it caused only 1 trial to be run). Then I assumed that the time spent on 
trials was the t_trial I estimated previously, so the time spent on updates is 
N * t_trial. 
t_update = (.023234 - (1000002 * 7.0045e-9)) / 1000002 = 1.623e-8 seconds
	   
    c) Based on your model, suggest a strategy for choosing the batch
       size.  How might you generalize this strategy to automatically
       choose batch sizes for different types of computational
       experiments?
	   
Wait, my model doesn't include batch size. Should it? Regardless, we can 
automatically look for the best batch size by scripting several runs of the code
with different batch size inputs (but the same number of processors) and then 
looking for the one with the fastest results.
    
3.  In the workq subdirectory of this directory, there is a basic work
    queue implementation.  Following the strategy outlined in the
    slides, add synchronization calls in the locations marked TODO.
    You should run the code to make sure it behaves as expected!
	
How do I know if the code behaves as expected? The printfs will be randomly
interleaved regardless of how the code runs, based on my experience with C 
concurrency.
