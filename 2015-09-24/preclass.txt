0.  How much time did you spend on this pre-class exercise, and when?
2 hours, Wednesday afternoon and evening.

1.  What are one or two points that you found least clear in the
    9/24 slide decks (including the narration)?

Some of the OpenMP examples were confusing and incompletely explained, and I
wish I could have been there to ask the lecturer questions. Why does #pragma 
omp for occur inside #pragma omp parallel, when omp "parallel for loops" are
described as "forking off several threads to complete the for loop in parallel"?
Doesn't this mean that each thread going through the outer #pragma omp parallel
will spawn several sub-threads when it gets to #pragma omp for? In that case, 
won't all the sub-threads clobber each other on their parent thread's single 
copy of my_dot? The task framework was also confusing at first, though I think
I get it after staring long enough: the #pragma omp parallel is followed 
immediately by a #pragma omp single in order to make a bunch of threads that 
have nothing to do, so they pick up the tasks that are created by the single 
thread when it does #pragma omp task, right?

There's a bug in the audio at the end of the second slideshow: "This is not-
this is not-this is not-normally details, but..."

2.  The omp_mc.c file in the demo subdirectory runs a Monte Carlo
    simulation to estimate the expected value of a uniform random
    variable.  The "-p" option sets the number of processors used,
    while "-b" sets the number of trials between synchronizations.

    a) Write a model for the run time for this simulation code in
       terms of the number of trials (N), number of processors (p),
       time per trial (t_trial), and time to update the global
       counters in the critical section (t_update).
	   
I'm guessing this question has the same problem a similar question on the last
pre-class questions had: it neglects to include a variable for the batch size,
which is important in determining the runtime. Assuming B is the batch size, we
still have 
Time in serial code = N / B * t_update
Time in parallel code = N / p * t_trial
Total time = N/B * t_update + N/p * t_trial

    b) Run the code with a few different parameter values in order
       to estimate N, t_trial, and t_update for this code on
       a totient compute node.
	   
I'll do this like we did in class last time.
	   
Trials: 
N = 10024000, B = 1000, p = 24, T = .05348015
N = 10048000, B = 2000, p = 24, T = .03424215
N = 10120000, B = 5000, p = 24, T = .07123995

This gives us the system of equations:
10024000 / 1000 * t_update + 10024000 / 24 * t_trial = .05348015
10048000 / 2000 * t_update + 10048000 / 24 * t_trial = .03424215
10120000 / 5000 * t_update + 10120000 / 24 * t_trial = .07123995

Unfortunately, I have no idea how to use MATLAB code to automatically solve this
like Dave did in class (I have never used MATLAB), so I'll have to do it by
hand. I don't know how to solve an overconstrained system by hand (how do I 
combine the extra data?), so I'll just throw out one of the equations and do 
basic algebra. Solving it with the first two equations, I get
t_trial = 3.5532e-8
t_update = 3.8547e-6
	   
    c) Based on your model, suggest a strategy for choosing the batch
       size.  How might you generalize this strategy to automatically
       choose batch sizes for different types of computational
       experiments?
	   
Now that we have these values, we can write T = N/B * 3.85e-6 + N/p * 3.55e-8.
Assuming a constant p, we would like N/B to be at least 100 times smaller than 
N/p, since t_update is (roughly) 100 times larger than t_trial. So, naively, we 
could say that the best batch size is 100*p. Of course, this doesn't really 
account for the fact that N grows linearly with B, so increasing B will also
increase N/p by virtue of increasing N. The best way to really solve this 
problem would be to get a concrete equation for N in terms of B, but I don't 
have time to do that right now.

3.  The "OpenMP pitfalls" paper describes some common pitfalls (both
    performance and correctness) in OpenMP codes.  Go through the
    checklist in the paper for omp_mc.c.  What performance mistakes
    are there in the demonstration implementation?
	
One of the mistakes listed is "using #critical when #atomic would be sufficient."
I don't know how #atomic works, but a quick Google for documentation shows that
it is intended to be used to "ensure a specific storage location is accessed 
atomically" and it has both "read" and "write" versions. Since the is_converged
function accesses the shared result object in a read-only manner, perhaps it 
could be guarded with #atomic read instead of being included in the critical 
section. If this works the way I think it does, it would allow all the threads
to concurrently read from the result object as long as no one was writing to it
(and writers would block on their critical sections as usual).

It could also just be the mistake of "putting too much work in the critical 
region." It's possible that the critical region that updates the global counters
could be shortened by clever use of more thread-local variables, like a 
reduction. Also, the critical region around seed = random() could be made 
unnecessary if we used a smarter random number generator that did not have 
global state, as suggested in class last time.


